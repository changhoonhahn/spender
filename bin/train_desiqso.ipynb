{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d049d93c-8f97-491c-9b93-70a206fa9167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from accelerate import Accelerator\n",
    "from spender import SpectrumAutoencoder\n",
    "from spender.data import desi_qso as desi \n",
    "from spender.util import mem_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172c7ccb-0d22-41d8-84a4-60b6fb753d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_train(seq,niter=800):\n",
    "    for d in seq:\n",
    "        if not \"iteration\" in d:d[\"iteration\"]=niter\n",
    "        if not \"encoder\" in d:d.update({\"encoder\":d[\"data\"]})\n",
    "    return seq\n",
    "\n",
    "def build_ladder(train_sequence):\n",
    "    n_iter = sum([item['iteration'] for item in train_sequence])\n",
    "\n",
    "    ladder = np.zeros(n_iter,dtype='int')\n",
    "    n_start = 0\n",
    "    for i,mode in enumerate(train_sequence):\n",
    "        n_end = n_start+mode['iteration']\n",
    "        ladder[n_start:n_end]= i\n",
    "        n_start = n_end\n",
    "    return ladder\n",
    "\n",
    "def get_all_parameters(models,instruments):\n",
    "    model_params = []\n",
    "    # multiple encoders\n",
    "    for model in models:\n",
    "        model_params += model.encoder.parameters()\n",
    "        \n",
    "    print(sum([p.numel() for p in model_params if p.requires_grad]))\n",
    "    # 1 decoder\n",
    "    model_params += model.decoder.parameters()\n",
    "    dicts = [{'params':model_params}]\n",
    "\n",
    "    n_parameters = sum([p.numel() for p in model_params if p.requires_grad])\n",
    "\n",
    "    instr_params = []\n",
    "    # instruments\n",
    "    for inst in instruments:\n",
    "        if inst==None:continue\n",
    "        instr_params += inst.parameters()\n",
    "        s = [p.numel() for p in inst.parameters()]\n",
    "    if instr_params != []:\n",
    "        dicts.append({'params':instr_params,'lr': 1e-4})\n",
    "        n_parameters += sum([p.numel() for p in instr_params if p.requires_grad])\n",
    "        print(\"parameter dict:\",dicts[1])\n",
    "    return dicts,n_parameters\n",
    "\n",
    "def restframe_weight(model,mu=5000,sigma=2000,amp=30):\n",
    "    x = model.decoder.wave_rest\n",
    "    return amp*torch.exp(-(0.5*(x-mu)/sigma)**2)\n",
    "\n",
    "def Loss(model, instrument, batch):\n",
    "    spec, w, z = batch\n",
    "    # need the latents later on if similarity=True\n",
    "    s = model.encode(spec)\n",
    "    \n",
    "    return model.loss(spec, w, instrument, z=z, s=s)\n",
    "\n",
    "def checkpoint(accelerator, args, optimizer, scheduler, n_encoder, outfile, losses):\n",
    "    unwrapped = [accelerator.unwrap_model(args_i).state_dict() for args_i in args]\n",
    "\n",
    "    accelerator.save({\n",
    "        \"model\": unwrapped,\n",
    "        \"losses\": losses,\n",
    "    }, outfile)\n",
    "    return\n",
    "\n",
    "def load_model(filename, models, instruments):\n",
    "    device = instruments[0].wave_obs.device\n",
    "    model_struct = torch.load(filename, map_location=device)\n",
    "    #wave_rest = model_struct['model'][0]['decoder.wave_rest']\n",
    "    for i, model in enumerate(models):\n",
    "        # backwards compat: encoder.mlp instead of encoder.mlp.mlp\n",
    "        if 'encoder.mlp.mlp.0.weight' in model_struct['model'][i].keys():\n",
    "            from collections import OrderedDict\n",
    "            model_struct['model'][i] = OrderedDict([(k.replace('mlp.mlp', 'mlp'), v) for k, v in model_struct['model'][i].items()])\n",
    "        # backwards compat: add instrument to encoder\n",
    "        try:\n",
    "            model.load_state_dict(model_struct['model'][i], strict=False)\n",
    "        except RuntimeError:\n",
    "            model_struct['model'][i]['encoder.instrument.wave_obs']= instruments[i].wave_obs\n",
    "            model_struct['model'][i]['encoder.instrument.skyline_mask']= instruments[i].skyline_mask\n",
    "            model.load_state_dict(model_struct[i]['model'], strict=False)\n",
    "\n",
    "    losses = model_struct['losses']\n",
    "    return models, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01671e9c-b53a-4cc9-b958-a988ebc83188",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restframe:\t1161 .. 9824 A (9780 bins)\n",
      "/tigress/chhahn/spender_qso/train\n"
     ]
    }
   ],
   "source": [
    "z_max = 2.1\n",
    "_dir = '/tigress/chhahn/spender_qso/train'\n",
    "outfile = '/tigress/chhahn/spender_qso/train/models/testing.pt'\n",
    "latents = 10 \n",
    "lr = 1e-3\n",
    "\n",
    "# define instruments\n",
    "instruments = [ desi.DESI() ]\n",
    "n_encoder = len(instruments)\n",
    "\n",
    "# data loaders\n",
    "batch_size = 256\n",
    "trainloaders = [ inst.get_data_loader(_dir, tag=\"qso_lowz\", which=\"train\",  batch_size=batch_size, shuffle=True, shuffle_instance=True) for inst in instruments ]\n",
    "validloaders = [ inst.get_data_loader(_dir,  tag=\"qso_lowz\", which=\"valid\", batch_size=batch_size, shuffle=True, shuffle_instance=True) for inst in instruments ]\n",
    "\n",
    "# restframe wavelength for reconstructed spectra\n",
    "# Note: represents joint dataset wavelength range\n",
    "lmbda_min = instruments[0].wave_obs[0]/(1.0+z_max) # 2000 A\n",
    "lmbda_max = instruments[0].wave_obs[-1] # 9824 A\n",
    "bins = 9780\n",
    "wave_rest = torch.linspace(lmbda_min, lmbda_max, bins, dtype=torch.float32)\n",
    "    \n",
    "print (\"Restframe:\\t{:.0f} .. {:.0f} A ({} bins)\".format(lmbda_min, lmbda_max, bins))\n",
    "\n",
    "print(_dir) \n",
    "\n",
    "\n",
    "# define training sequence\n",
    "FULL = {\"data\":[True],\"decoder\":True}\n",
    "train_sequence = prepare_train([FULL])\n",
    "\n",
    "# define and train the model\n",
    "n_hidden = (64, 128, 1024)\n",
    "models = [ SpectrumAutoencoder(instrument,\n",
    "                               wave_rest,\n",
    "                               n_latent=latents,\n",
    "                               n_hidden=n_hidden,\n",
    "                               act=[nn.LeakyReLU()]*(len(n_hidden)+1)\n",
    "                               )\n",
    "          for instrument in instruments ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "930ee253-7975-4fbc-a16c-b9b88c564621",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.device_count(): 1\n",
      "--- Model /tigress/chhahn/spender_qso/train/models/testing.pt ---\n"
     ]
    }
   ],
   "source": [
    "n_epoch = sum([item['iteration'] for item in train_sequence])\n",
    "init_t = time.time()\n",
    "print(\"torch.cuda.device_count():\",torch.cuda.device_count())\n",
    "print (f\"--- Model {outfile} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1165a2b9-bc5d-4cfd-bce1-f4865ed74cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3159178\n",
      "model parameters: 13324798\n",
      "CPU RAM Free: 796.7 GB\n",
      "GPU 0 ... Mem Free: 40506MB / 40960MB | Utilization   0%\n"
     ]
    }
   ],
   "source": [
    "n_encoder = len(models)\n",
    "model_parameters, n_parameters = get_all_parameters(models,instruments)\n",
    "\n",
    "print(\"model parameters:\", n_parameters)\n",
    "mem_report()\n",
    "\n",
    "ladder = build_ladder(train_sequence)\n",
    "optimizer = torch.optim.Adam(model_parameters, lr=lr, eps=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, lr,\n",
    "                                          total_steps=n_epoch)\n",
    "\n",
    "accelerator = Accelerator(mixed_precision='fp16')\n",
    "models = [accelerator.prepare(model) for model in models]\n",
    "instruments = [accelerator.prepare(instrument) for instrument in instruments]\n",
    "trainloaders = [accelerator.prepare(loader) for loader in trainloaders]\n",
    "validloaders = [accelerator.prepare(loader) for loader in validloaders]\n",
    "optimizer = accelerator.prepare(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b61d2e7-516c-4a27-bcab-448e05313c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU RAM Free: 795.7 GB\n",
      "GPU 0 ... Mem Free: 39886MB / 40960MB | Utilization   2%\n",
      "====> Epoch: 0\n",
      "TRAINING Losses: (11.940950007530713,)\n",
      "VALIDATION Losses: (12.78382681512688,)\n",
      "CPU RAM Free: 794.0 GB\n",
      "GPU 0 ... Mem Free: 16204MB / 40960MB | Utilization  59%\n",
      "====> Epoch: 1\n",
      "TRAINING Losses: (11.71884135388156,)\n",
      "VALIDATION Losses: (12.611339784035106,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 16202MB / 40960MB | Utilization  59%\n",
      "====> Epoch: 2\n",
      "TRAINING Losses: (9.090837845454892,)\n",
      "VALIDATION Losses: (8.020053036817343,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 16202MB / 40960MB | Utilization  59%\n",
      "====> Epoch: 3\n",
      "TRAINING Losses: (6.076129480193752,)\n",
      "VALIDATION Losses: (6.048764365369714,)\n",
      "CPU RAM Free: 794.0 GB\n",
      "GPU 0 ... Mem Free: 16202MB / 40960MB | Utilization  59%\n",
      "====> Epoch: 4\n",
      "TRAINING Losses: (4.21785553758295,)\n",
      "VALIDATION Losses: (3.987391852109502,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 16202MB / 40960MB | Utilization  59%\n",
      "====> Epoch: 5\n",
      "TRAINING Losses: (4.021403152058578,)\n",
      "VALIDATION Losses: (3.328956984341003,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 7472MB / 40960MB | Utilization  81%\n",
      "====> Epoch: 6\n",
      "TRAINING Losses: (3.051248783445996,)\n",
      "VALIDATION Losses: (2.7853464518625106,)\n",
      "CPU RAM Free: 794.0 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 7\n",
      "TRAINING Losses: (2.363693441004126,)\n",
      "VALIDATION Losses: (1.993275579915377,)\n",
      "CPU RAM Free: 794.0 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 8\n",
      "TRAINING Losses: (2.0663056203444268,)\n",
      "VALIDATION Losses: (1.8399728387821892,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 9\n",
      "TRAINING Losses: (1.6417913030189186,)\n",
      "VALIDATION Losses: (1.5646959097180027,)\n",
      "CPU RAM Free: 794.0 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 10\n",
      "TRAINING Losses: (1.4546993459386175,)\n",
      "VALIDATION Losses: (1.1900639625863574,)\n",
      "CPU RAM Free: 794.0 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 11\n",
      "TRAINING Losses: (1.2678130361157491,)\n",
      "VALIDATION Losses: (1.1390343821337174,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 12\n",
      "TRAINING Losses: (1.0205700936210744,)\n",
      "VALIDATION Losses: (1.0116624162375534,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 13\n",
      "TRAINING Losses: (0.9745984474097708,)\n",
      "VALIDATION Losses: (0.9334913761541628,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 14\n",
      "TRAINING Losses: (0.8734218817813301,)\n",
      "VALIDATION Losses: (0.880114802214213,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 15\n",
      "TRAINING Losses: (0.8486789277203661,)\n",
      "VALIDATION Losses: (0.9575127038534508,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 16\n",
      "TRAINING Losses: (0.8201936189680802,)\n",
      "VALIDATION Losses: (0.8372216812565014,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 17\n",
      "TRAINING Losses: (0.7928289137725303,)\n",
      "VALIDATION Losses: (0.9037649788316173,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 18\n",
      "TRAINING Losses: (0.7806137738473831,)\n",
      "VALIDATION Losses: (0.7179420528541376,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 19\n",
      "TRAINING Losses: (0.7378171811606972,)\n",
      "VALIDATION Losses: (0.7924063233924585,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 20\n",
      "TRAINING Losses: (0.6842957064431161,)\n",
      "VALIDATION Losses: (0.6960501203464936,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 21\n",
      "TRAINING Losses: (0.7612842133762274,)\n",
      "VALIDATION Losses: (0.6835904245551289,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 22\n",
      "TRAINING Losses: (0.7591017544895087,)\n",
      "VALIDATION Losses: (0.7787131837015584,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 23\n",
      "TRAINING Losses: (0.7709298227462092,)\n",
      "VALIDATION Losses: (0.7450099768521397,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 24\n",
      "TRAINING Losses: (0.767363974943148,)\n",
      "VALIDATION Losses: (0.7415026627552626,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 25\n",
      "TRAINING Losses: (0.7188576895134519,)\n",
      "VALIDATION Losses: (0.6762960511749815,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 26\n",
      "TRAINING Losses: (0.7385726071498799,)\n",
      "VALIDATION Losses: (0.7414336029457153,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 27\n",
      "TRAINING Losses: (0.7198294482280465,)\n",
      "VALIDATION Losses: (0.7371276020442188,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 28\n",
      "TRAINING Losses: (0.7185244804837241,)\n",
      "VALIDATION Losses: (0.7048730681529811,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n",
      "====> Epoch: 29\n",
      "TRAINING Losses: (0.6921235667253715,)\n",
      "VALIDATION Losses: (0.7266845971532783,)\n",
      "CPU RAM Free: 793.9 GB\n",
      "GPU 0 ... Mem Free: 1652MB / 40960MB | Utilization  95%\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/chhahn/projects/spender_qso/spender/util.py\", line 201, in interp1d\n        torch.jit.fork(interp1d_single, x[i], y[i], target[i], mask) for i in range(bs)\n    ]\n    itp = torch.stack([torch.jit.wait(f) for f in futures])\n                       ~~~~~~~~~~~~~~ <--- HERE\n\n    return itp\nRuntimeError: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/chhahn/projects/spender_qso/spender/util.py\", line 199, in <forked function>\n    # this is apparantly how parallelism works in pytorch?\n    futures = [\n        torch.jit.fork(interp1d_single, x[i], y[i], target[i], mask) for i in range(bs)\n        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    ]\n    itp = torch.stack([torch.jit.wait(f) for f in futures])\n  File \"/home/chhahn/projects/spender_qso/spender/util.py\", line 129, in interp1d_single\n    b = y[:-1] - (m * x[:-1])\n\n    idx = torch.sum(torch.ge(target[:, None], x[None, :]), 1) - 1\n          ~~~~~~~~~ <--- HERE\n    idx = torch.clamp(idx, 0, len(m) - 1)\nRuntimeError: CUDA out of memory. Tried to allocate 582.00 MiB (GPU 0; 39.56 GiB total capacity; 36.85 GiB already allocated; 518.00 MiB free; 38.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dbbe5e984379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mn_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstruments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-ad9f2fd1156a>\u001b[0m in \u001b[0;36mLoss\u001b[0;34m(model, instrument, batch)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstrument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/spender_qso/spender/model.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, y, w, instrument, z, s, normalize, individual)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mfloat\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mweighted\u001b[0m \u001b[0mMSE\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstrument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstrument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindividual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindividual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gqp/lib/python3.7/site-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gqp/lib/python3.7/site-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gqp/lib/python3.7/site-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'@autocast() decorator is not supported in script mode'\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/spender_qso/spender/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y, instrument, z, s, normalize, weights)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mBatch\u001b[0m \u001b[0mof\u001b[0m \u001b[0mspectra\u001b[0m \u001b[0mat\u001b[0m \u001b[0mredshift\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mz\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mobserved\u001b[0m \u001b[0mby\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0minstrument\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \"\"\"\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstrument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstrument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/spender_qso/spender/model.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, y, instrument, z, s, normalize, weights)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mrestframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;31m# make resampled and interpolated reconstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mreconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstrument\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstrument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;31m# normalize restframe and reconstruction to observed spectrum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/spender_qso/spender/model.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, x, instrument, z)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mwave_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstrument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwave_obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mspectrum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minterp1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwave_redshifted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwave_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;31m# convolve with LSF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/chhahn/projects/spender_qso/spender/util.py\", line 201, in interp1d\n        torch.jit.fork(interp1d_single, x[i], y[i], target[i], mask) for i in range(bs)\n    ]\n    itp = torch.stack([torch.jit.wait(f) for f in futures])\n                       ~~~~~~~~~~~~~~ <--- HERE\n\n    return itp\nRuntimeError: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/home/chhahn/projects/spender_qso/spender/util.py\", line 199, in <forked function>\n    # this is apparantly how parallelism works in pytorch?\n    futures = [\n        torch.jit.fork(interp1d_single, x[i], y[i], target[i], mask) for i in range(bs)\n        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ <--- HERE\n    ]\n    itp = torch.stack([torch.jit.wait(f) for f in futures])\n  File \"/home/chhahn/projects/spender_qso/spender/util.py\", line 129, in interp1d_single\n    b = y[:-1] - (m * x[:-1])\n\n    idx = torch.sum(torch.ge(target[:, None], x[None, :]), 1) - 1\n          ~~~~~~~~~ <--- HERE\n    idx = torch.clamp(idx, 0, len(m) - 1)\nRuntimeError: CUDA out of memory. Tried to allocate 582.00 MiB (GPU 0; 39.56 GiB total capacity; 36.85 GiB already allocated; 518.00 MiB free; 38.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n"
     ]
    }
   ],
   "source": [
    "# track training and validation loss\n",
    "detailed_loss = np.zeros((2, n_encoder, n_epoch))\n",
    "\n",
    "for epoch_ in range(n_epoch):\n",
    "    mem_report()\n",
    "    mode = train_sequence[ladder[epoch_]]\n",
    "\n",
    "    # turn on/off model decoder\n",
    "    for p in models[0].decoder.parameters():\n",
    "        p.requires_grad = True #mode['decoder']\n",
    "\n",
    "    # turn on/off encoder\n",
    "    for p in models[0].encoder.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    models[0].train()\n",
    "    instruments[0].train()\n",
    "\n",
    "    n_sample = 0\n",
    "    for k, batch in enumerate(trainloaders[0]):\n",
    "        loss = Loss(models[0], instruments[0], batch)\n",
    "        \n",
    "        accelerator.backward(loss)\n",
    "        # clip gradients: stabilizes training with similarity\n",
    "        accelerator.clip_grad_norm_(model_parameters[0]['params'], 1.0)\n",
    "        # once per batch\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # logging: training\n",
    "        detailed_loss[0,0,epoch_] += loss #tuple( l.item() if hasattr(l, 'item') else 0 for l in losses )\n",
    "        n_sample += batch_size\n",
    "\n",
    "    detailed_loss[0,0,epoch_] /= n_sample\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        models[0].eval()\n",
    "        instruments[0].eval()\n",
    "\n",
    "        n_sample = 0\n",
    "        for k, batch in enumerate(validloaders[0]):\n",
    "            loss = Loss(models[0], instruments[0], batch)\n",
    "            # logging: validation\n",
    "            detailed_loss[1,0,epoch_] += loss #tuple( l.item() if hasattr(l, 'item') else 0 for l in losses )\n",
    "            n_sample += batch_size\n",
    "\n",
    "        detailed_loss[1,0,epoch_] /= n_sample\n",
    "\n",
    "    losses = tuple(detailed_loss[0, :, epoch_])\n",
    "    vlosses = tuple(detailed_loss[1, :, epoch_])\n",
    "    print('====> Epoch: %i' % (epoch_))\n",
    "    print('TRAINING Losses:', losses)\n",
    "    print('VALIDATION Losses:', vlosses)\n",
    "\n",
    "    #if epoch_ % 5 == 0 or epoch_ == n_epoch - 1:\n",
    "    #    args = models\n",
    "    #    checkpoint(accelerator, args, optimizer, scheduler, n_encoder, outfile, detailed_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195b5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6f299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gqp [~/.conda/envs/gqp/]",
   "language": "python",
   "name": "conda_gqp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
